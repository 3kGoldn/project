# -*- coding: utf-8 -*-
"""“InstantMesh最终版本

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HrMSEUTO4oM2h24i3h0lbYftjXZyd5T7
"""

# Commented out IPython magic to ensure Python compatibility.
# %cd /content
!GIT_LFS_SKIP_SMUDGE=1 git clone -b dev https://github.com/camenduru/InstantMesh
# %cd /content/InstantMesh

!pip install pytorch-lightning==2.1.2 gradio==3.50.2 einops omegaconf torchmetrics webdataset accelerate tensorboard
!pip install PyMCubes trimesh rembg transformers diffusers==0.33.1 bitsandbytes imageio[ffmpeg] xatlas plyfile
!pip install git+https://github.com/NVlabs/nvdiffrast jax==0.6.0 jaxlib==0.6.0 ninja
!pip install onnxruntime
!pip install --upgrade huggingface_hub==0.30.2

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/InstantMesh

# 首先修复依赖关系
!pip uninstall -y numpy transformers diffusers
!pip install numpy==1.26.4 transformers==4.38.2 diffusers==0.33.1
!pip install --upgrade rembg>=2.0.50 pytorch-lightning==2.1.2 gradio==3.50.2 einops omegaconf torchmetrics webdataset accelerate tensorboard

import torch
model = None
torch.cuda.empty_cache()

import numpy as np
import rembg
from PIL import Image
from pytorch_lightning import seed_everything
from einops import rearrange
from diffusers import DiffusionPipeline, EulerAncestralDiscreteScheduler
from huggingface_hub import hf_hub_download
from src.utils.infer_util import remove_background, resize_foreground
from google.colab import files
import os

# 初始化pipeline
try:
    pipeline = DiffusionPipeline.from_pretrained(
        "sudo-ai/zero123plus-v1.2",
        custom_pipeline="zero123plus",
        torch_dtype=torch.float16
    )
    pipeline.scheduler = EulerAncestralDiscreteScheduler.from_config(
        pipeline.scheduler.config,
        timestep_spacing='trailing'
    )
    unet_ckpt_path = hf_hub_download(
        repo_id="TencentARC/InstantMesh",
        filename="diffusion_pytorch_model.bin",
        repo_type="model"
    )
    state_dict = torch.load(unet_ckpt_path, map_location='cpu')
    pipeline.unet.load_state_dict(state_dict, strict=True)
    device = torch.device('cuda')
    pipeline = pipeline.to(device)
    seed_everything(0)
except Exception as e:
    print(f"初始化pipeline失败: {e}")
    raise

def preprocess(input_image, do_remove_background):
    try:
        rembg_session = rembg.new_session() if do_remove_background else None
        if do_remove_background:
            input_image = remove_background(input_image, rembg_session)
            input_image = resize_foreground(input_image, 0.85)
        return input_image
    except Exception as e:
        print(f"图像预处理失败: {e}")
        raise

def generate_six_views(input_image, sample_steps, sample_seed, output_dir):
    """生成6张新视角图并保存到指定目录"""
    try:
        seed_everything(sample_seed)
        generator = torch.Generator(device=device)

        z123_image = pipeline(
            input_image,
            num_inference_steps=sample_steps,
            generator=generator,
        ).images[0]

        images_array = np.array(z123_image)
        images_tensor = torch.from_numpy(images_array)
        single_images = rearrange(images_tensor, '(n h) (m w) c -> (n m) h w c', n=3, m=2, h=320, w=320)

        os.makedirs(output_dir, exist_ok=True)

        view_names = ['front', 'front_right', 'right', 'back', 'left', 'front_left']
        for idx, img in enumerate(single_images):
            img_pil = Image.fromarray(img.numpy())
            img_pil.save(f"{output_dir}/{view_names[idx]}.png")

        composite = rearrange(single_images, '(n m) h w c -> (n h) (m w) c', n=2, m=3)
        composite_pil = Image.fromarray(composite.numpy())
        composite_pil.save(f"{output_dir}/composite.png")

        return single_images, composite_pil
    except Exception as e:
        print(f"生成视角图失败: {e}")
        raise

# 1. 处理主视图
print("=== 第一步：请上传主视图 ===")
try:
    uploaded = files.upload()
    input_image = Image.open(list(uploaded.keys())[0])
    processed_image = preprocess(input_image, do_remove_background=True)
    print("主视图预处理结果:")
    display(processed_image)

    os.makedirs("/content/InstantMesh/outputs/main_views", exist_ok=True)
    single_images_main, composite_main = generate_six_views(
        processed_image, 75, 42, "/content/InstantMesh/outputs/main_views"
    )
    print("✅ 主视图生成的6张视角图已保存到 /outputs/main_views/")
    print("2×3拼接预览图:")
    display(composite_main)
except Exception as e:
    print(f"主视图处理失败: {e}")

# 2. 处理侧视图
print("\n=== 第二步：请上传侧视图 ===")
try:
    uploaded = files.upload()
    input_image = Image.open(list(uploaded.keys())[0])
    processed_image = preprocess(input_image, do_remove_background=True)
    print("侧视图预处理结果:")
    display(processed_image)

    os.makedirs("/content/InstantMesh/outputs/side_views", exist_ok=True)
    single_images_side, composite_side = generate_six_views(
        processed_image, 75, 42, "/content/InstantMesh/outputs/side_views"
    )
    print("✅ 侧视图生成的6张视角图已保存到 /outputs/side_views/")
    print("2×3拼接预览图:")
    display(composite_side)
except Exception as e:
    print(f"侧视图处理失败: {e}")

# 3. 处理背视图
print("\n=== 第三步：请上传背视图 ===")
try:
    uploaded = files.upload()
    input_image = Image.open(list(uploaded.keys())[0])
    processed_image = preprocess(input_image, do_remove_background=True)
    print("背视图预处理结果:")
    display(processed_image)

    os.makedirs("/content/InstantMesh/outputs/back_views", exist_ok=True)
    single_images_back, composite_back = generate_six_views(
        processed_image, 75, 42, "/content/InstantMesh/outputs/back_views"
    )
    print("✅ 背视图生成的6张视角图已保存到 /outputs/back_views/")
    print("2×3拼接预览图:")
    display(composite_back)
except Exception as e:
    print(f"背视图处理失败: {e}")

print("\n=== 处理完成 ===")

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/InstantMesh

import torch
pipeline = None
torch.cuda.empty_cache()

import os
from torchvision.transforms import v2
from huggingface_hub import hf_hub_download
from omegaconf import OmegaConf
from PIL import Image
import numpy as np
from einops import rearrange, repeat
import tempfile
from tqdm import tqdm

from src.utils.train_util import instantiate_from_config
from src.utils.camera_util import (FOV_to_intrinsics, get_zero123plus_input_cameras)
from src.utils.mesh_util import save_obj, save_obj_with_mtl

config_path = 'configs/instant-mesh-base.yaml'
config = OmegaConf.load(config_path)
config_name = os.path.basename(config_path).replace('.yaml', '')
model_config = config.model_config
infer_config = config.infer_config
model_ckpt_path = hf_hub_download(repo_id="TencentARC/InstantMesh", filename="instant_mesh_base.ckpt", repo_type="model")
model = instantiate_from_config(model_config)
state_dict = torch.load(model_ckpt_path, map_location='cpu')['state_dict']
state_dict = {k[14:]: v for k, v in state_dict.items() if k.startswith('lrm_generator.') and 'source_camera' not in k}
model.load_state_dict(state_dict, strict=True)
device = torch.device('cuda')
model = model.to(device)
IS_FLEXICUBES = True if config_name.startswith('instant-mesh') else False
if IS_FLEXICUBES:
    model.init_flexicubes_geometry(device, fovy=30.0)
model = model.eval()

def make_mesh(mesh_fpath, planes):
    mesh_basename = os.path.basename(mesh_fpath).split('.')[0]
    mesh_dirname = os.path.dirname(mesh_fpath)
    with torch.no_grad():
        mesh_out = model.extract_mesh(planes, use_texture_map=True, **infer_config)
        vertices, faces, uvs, mesh_tex_idx, tex_map = mesh_out
        save_obj_with_mtl(
            vertices.data.cpu().numpy(),
            uvs.data.cpu().numpy(),
            faces.data.cpu().numpy(),
            mesh_tex_idx.data.cpu().numpy(),
            tex_map.permute(1, 2, 0).data.cpu().numpy(),
            mesh_fpath,
        )
        print(f"Mesh with texmap saved to {mesh_fpath}")
    return mesh_fpath

def generate_model(images):
    images = np.asarray(images, dtype=np.float32) / 255.0
    images = torch.from_numpy(images).permute(2, 0, 1).contiguous().float()     # (3, 960, 640)
    images = rearrange(images, 'c (n h) (m w) -> (n m) c h w', n=3, m=2)        # (6, 3, 320, 320)
    input_cameras = get_zero123plus_input_cameras(batch_size=1, radius=4.0).to(device)

    images = images.unsqueeze(0).to(device)
    images = v2.functional.resize(images, (320, 320), interpolation=3, antialias=True).clamp(0, 1)

    directory = '/content/tmp'
    if not os.path.exists(directory):
        os.makedirs(directory)
    tempfile.tempdir = directory
    mesh_fpath = tempfile.NamedTemporaryFile(suffix=".obj", delete=False).name

    with torch.no_grad():
        planes = model.forward_planes(images, input_cameras)
        mesh_fpath = make_mesh(mesh_fpath, planes)

    return mesh_fpath

# 列出所有生成的图片
main_view_dir = '/content/InstantMesh/outputs/main_views'
side_view_dir = '/content/InstantMesh/outputs/side_views'
back_view_dir = '/content/InstantMesh/outputs/back_views'

all_images = []
for view_dir in [main_view_dir, side_view_dir, back_view_dir]:
    for img_name in os.listdir(view_dir):
        if img_name.endswith('.png'):
            all_images.append(os.path.join(view_dir, img_name))

print("以下是生成的18张图片：")
for i, img_path in enumerate(all_images):
    print(f"{i + 1}. {img_path}")

# 让用户选择6张图片
selected_indices = []
while len(selected_indices) < 6:
    try:
        index = int(input(f"请输入第 {len(selected_indices) + 1} 张要选择的图片编号 (1 - 18): ")) - 1
        if 0 <= index < 18 and index not in selected_indices:
            selected_indices.append(index)
        else:
            print("无效的选择，请重新输入。")
    except ValueError:
        print("输入无效，请输入一个数字。")

selected_images = [Image.open(all_images[i]) for i in selected_indices]

# 将6张图片拼接成一张大图
width, height = selected_images[0].size
new_image = Image.new('RGB', (width * 2, height * 3))
for i in range(3):
    for j in range(2):
        new_image.paste(selected_images[i * 2 + j], (j * width, i * height))

output_model_obj = generate_model(new_image)
!cp -f {output_model_obj} /content/InstantMesh/output_model.obj
print(f"✅ OBJ模型已生成并保存到 /content/InstantMesh/output_model.obj")